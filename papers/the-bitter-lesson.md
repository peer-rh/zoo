---
aliases: 
tags:
  - "#ai"
4 Sentence Summary: Richard Sutton states that historically most/all progress in AI has stemmed from either scaling up existing solutions or coming up with new general-solution algorithms
Citation: "R. Sutton, “The Bitter Lesson.” Accessed: Feb. 22, 2024. [Online]. Available: [http://www.incompleteideas.net/IncIdeas/BitterLesson.html](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)"
---
- Sutton states that historically algorithms which could leverage scaling compute almost always outperform specialised algorithms
- He lists examples of Chess, Go, and speech recognition, where brute-force/search algorithms outperformed hand-crafted algorithms
- He suggests, that although intuitive it is not good to include hand-crafted knowledge in ML algorithms, since usually this only leads to short-term gains
- Sutton is of the opinion that we shouldn't try to model the brain/create algorithms to emulate intelligence and instead only focus on meta-algorithms, which will create those algorithms for us, since intelligence is too complex for us to fully understand/implement
